(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{450:function(e,a,o){"use strict";o.r(a);var r=o(56),s=Object(r.a)({},(function(){var e=this,a=e.$createElement,o=e._self._c||a;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h2",{attrs:{id:"tensorflowjs"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#tensorflowjs"}},[e._v("#")]),e._v(" TensorflowJS")]),e._v(" "),o("p",[e._v("O TensorFlow.js é uma biblioteca JavaScript acelerada por hardware de código aberto para treinamento e implantação de modelos de aprendizado de máquina.")]),e._v(" "),o("h2",{attrs:{id:"o-projeto"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#o-projeto"}},[e._v("#")]),e._v(" O projeto")]),e._v(" "),o("p",[e._v("O projeto consiste num site em que é possível enviar uma imagem e obter como resultado qual a possibilidade de determinados elementos estarem nelas. A ideia é que toda a rede neural seja carregada "),o("strong",[e._v("client side")]),e._v(", ou seja, no próprio navegador do usuário. Isso é possível graças ao TensorflowJS e abre possibilidades interssantes, como o uso do hardware do usuário, possibilidade de se usar um celular, além de trazer "),o("a",{attrs:{href:"https://www.quora.com/What-are-the-advantages-of-running-a-Machine-Learning-algorithm-using-a-Javascript-ML-library-like-Tensorflow-js-Isnt-better-to-train-a-model-on-the-server-side",target:"_blank",rel:"noopener noreferrer"}},[e._v("maior privacidade"),o("OutboundLink")],1)]),e._v(" "),o("p",[e._v("Os modelos utilizados, "),o("a",{attrs:{href:"#vgg16"}},[e._v("VGG16")]),e._v(" e "),o("a",{attrs:{href:"#mobilenet"}},[e._v("MobileNet")]),e._v(", foram importados do Keras e convertidos para um modelo tfjs usando um "),o("a",{attrs:{href:"https://github.com/ebmm01/tensorflowjs/blob/master/keras_conversor/keras_conversor.pyhttps://github.com/ebmm01/tensorflowjs/blob/master/keras_conversor/keras_conversor.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("script python"),o("OutboundLink")],1),e._v(". Vale salientar que é recomendado o uso do MobileNet, visto que ele já é adpatado para uso mobile (o que pode ser visto pelo seu próprio tamanho, 16mb vs 500mb do VGG16).")]),e._v(" "),o("h3",{attrs:{id:"breve-explicacao-sobre-os-modelos-utilizados"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#breve-explicacao-sobre-os-modelos-utilizados"}},[e._v("#")]),e._v(" Breve explicação sobre os modelos utilizados")]),e._v(" "),o("h4",{attrs:{id:"vgg16"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#vgg16"}},[e._v("#")]),e._v(" VGG16")]),e._v(" "),o("p",[e._v("VGG16 é um rede neural convolucional para reconhecimento de objetos desenvolvido e treinando pelo grupo de Oxford, "),o("em",[e._v("Visual Geometry Group")]),e._v(" (VGG). Ele venceu a competição "),o("a",{attrs:{href:"http://www.image-net.org/challenges/LSVRC/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ILSVR (Imagenet)"),o("OutboundLink")],1),e._v(" em 2014, e é considerada uma das excelentes arquiteturas de modelos de visão até hoje.")]),e._v(" "),o("h4",{attrs:{id:"mobilenet"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#mobilenet"}},[e._v("#")]),e._v(" MobileNet")]),e._v(" "),o("p",[e._v("As MobileNets são modelos pequenos, de baixa latência e baixa potência, parametrizados para atender às restrições de recursos de vários casos de uso. Eles podem ser construídos para classificação, detecção, incorporação e segmentação semelhantes à forma como outros modelos populares de larga escala, como o Inception, são usados.")]),e._v(" "),o("p",[e._v("As MobileNets trocam entre latência, tamanho e precisão, comparando favoravelmente com modelos populares da literatura.")]),e._v(" "),o("h3",{attrs:{id:"algumas-funcoes-utilizadas"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#algumas-funcoes-utilizadas"}},[e._v("#")]),e._v(" Algumas funções utilizadas")]),e._v(" "),o("p",[o("strong",[e._v("fromPixels")]),e._v(" => Cria um tensor a partir de uma imagem.")]),e._v(" "),o("p",[o("strong",[e._v("resizeNearestNeighbor")]),e._v(" => Redimensiona um lote de imagens 3D para uma nova forma (224x224).")]),e._v(" "),o("p",[o("strong",[e._v("loadLayersModel")]),e._v(" => Carregar um modelo composto por Layers, incluindo sua topologia e pesos opcionais.")]),e._v(" "),o("p",[o("strong",[e._v("toFloat")]),e._v(" => Converte o tipo para float32.")]),e._v(" "),o("p",[o("strong",[e._v("expandDims")]),e._v(" => Expande a dimensão do tensor.")]),e._v(" "),o("p",[o("strong",[e._v("reverse")]),e._v(" => Inverte um tensor ao longo de um eixo especificado.")]),e._v(" "),o("p",[o("strong",[e._v("tensor1d")]),e._v(" => Cria um tensor unidimensional (Rank-1) com os valores, tamanho e dtype fornecidos.")]),e._v(" "),o("p",[o("strong",[e._v("scalar")]),e._v(" => Cria Tensor rank-0 (escalar)")]),e._v(" "),o("p",[o("strong",[e._v("sub")]),e._v(" => Subtrai dois Tensores elemento a elemento, A - B.")]),e._v(" "),o("p",[o("strong",[e._v("div")]),e._v(" => Divide dois Tensores elemento a elemento, A/B.")]),e._v(" "),o("h2",{attrs:{id:"referencias"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#referencias"}},[e._v("#")]),e._v(" Referências")]),e._v(" "),o("p",[o("a",{attrs:{href:"https://www.tensorflow.org/js",target:"_blank",rel:"noopener noreferrer"}},[e._v("TensorFlowJS"),o("OutboundLink")],1)]),e._v(" "),o("p",[o("a",{attrs:{href:"https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c",target:"_blank",rel:"noopener noreferrer"}},[e._v("Step by step VGG16 implementation in Keras for beginners"),o("OutboundLink")],1)]),e._v(" "),o("p",[o("a",{attrs:{href:"https://www.quora.com/What-is-the-VGG-neural-network",target:"_blank",rel:"noopener noreferrer"}},[e._v("What is the VGG neural network?"),o("OutboundLink")],1)]),e._v(" "),o("p",[o("a",{attrs:{href:"https://github.com/tensorflow/tfjs-models/tree/master/mobilenet",target:"_blank",rel:"noopener noreferrer"}},[e._v("MobileNet Github"),o("OutboundLink")],1)]),e._v(" "),o("p",[e._v("Olga Russakovsky*, Jia Deng*, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg and Li Fei-Fei. "),o("strong",[o("a",{attrs:{href:"http://www.image-net.org/challenges/LSVRC/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ImageNet Large Scale Visual Recognition Challenge"),o("OutboundLink")],1)]),e._v(". IJCV, 2015")])])}),[],!1,null,null,null);a.default=s.exports}}]);