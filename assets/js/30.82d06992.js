(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{453:function(e,t,a){"use strict";a.r(t);var s=a(56),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"pedestres"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pedestres"}},[e._v("#")]),e._v(" Pedestres")]),e._v(" "),a("p",[e._v("Datasets que envolvem pedestres, obstruídos ou não.")]),e._v(" "),a("h3",{attrs:{id:"cvc-05-partially-occluded-pedestrian-dataset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cvc-05-partially-occluded-pedestrian-dataset"}},[e._v("#")]),e._v(" CVC-05 Partially Occluded Pedestrian Dataset")]),e._v(" "),a("p",[a("img",{attrs:{src:"http://adas.cvc.uab.es/elektra/wp-content/uploads/sites/13/2016/05/CVC05_Frame.png",alt:""}})]),e._v(" "),a("p",[a("strong",[e._v("Fonte:")]),e._v(" "),a("a",{attrs:{href:"http://adas.cvc.uab.es/elektra/enigma-portfolio/cvc-05-partially-occluded-pedestrian-dataset/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://adas.cvc.uab.es/elektra/enigma-portfolio/cvc-05-partially-occluded-pedestrian-dataset/"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("strong",[e._v("Sobre:")]),e._v(" Este é um conjunto de dados de pedestres parcialmente obstruídos. O conjunto de dados consiste em 593 quadros positivos com pedestres anotados (com seus espelhos horizontais correspondentes).")]),e._v(" "),a("p",[a("strong",[e._v("Citação:")]),e._v(' J. Marín, D. Vázquez, A.M. López, J. Amores and L.I. Kuncheva, "Occlusion handling via random subspace classifiers for human detection", In IEEE Transactions on Systems, Man, and Cybernetics (Part B), 2013.')]),e._v(" "),a("h3",{attrs:{id:"daimler-pedestrian-detection-benchmark-dataset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#daimler-pedestrian-detection-benchmark-dataset"}},[e._v("#")]),e._v(" Daimler Pedestrian Detection Benchmark Dataset")]),e._v(" "),a("p",[a("img",{attrs:{src:"http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Daimler_Multi-Cue_Occluded_Ped/multi_cue_2.jpg",alt:""}})]),e._v(" "),a("p",[a("strong",[e._v("Fonte:")]),e._v(" "),a("a",{attrs:{href:"http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Daimler_Multi-Cue_Occluded_Ped/daimler_multi-cue_occluded_ped.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Daimler_Multi-Cue_Occluded_Ped/daimler_multi-cue_occluded_ped.html"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("strong",[e._v("Sobre:")]),e._v(" Os exemplos de treino e testes consistem em "),a("em",[e._v("bounding boxes")]),e._v(" rotuladas manualmente para pedestres e não-pedestres em imagens capturadas de um equipamento de câmera calibrado montado em um veículo em um ambiente urbano.")]),e._v(" "),a("p",[a("strong",[e._v("Citação:")]),e._v(" M. Enzweiler, A. Eigenstetter, B. Schiele and D. M. Gavrila,\nMulti-Cue Pedestrian Classification with Partial Occlusion Handling,\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010.")]),e._v(" "),a("h3",{attrs:{id:"cuhk-occlusion-dataset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cuhk-occlusion-dataset"}},[e._v("#")]),e._v(" CUHK Occlusion Dataset")]),e._v(" "),a("p",[a("img",{attrs:{src:"http://mmlab.ie.cuhk.edu.hk/images/datasets/cuhk_occlusion_large.jpg",alt:""}})]),e._v(" "),a("p",[a("strong",[e._v("Fonte:")]),e._v(" "),a("a",{attrs:{href:"http://mmlab.ie.cuhk.edu.hk/datasets/cuhk_occlusion/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://mmlab.ie.cuhk.edu.hk/datasets/cuhk_occlusion/index.html"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("strong",[e._v("Sobre:")]),e._v(" O conjunto de dados de oclusão CUHK é para pesquisas sobre análise de atividade e cenas lotadas. Este conjunto de dados contém 1.063 imagens com pedestres obstruídos dos conjuntos de dados do Caltech [1], ETHZ [2], TUD-Bruxelas [3], INRIA [4], Caviar [5] e imagens coletadas pelo MMLab")]),e._v(" "),a("p",[a("strong",[e._v("Citação:")]),e._v(" A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling W. Ouyang and X. Wang IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), 2012")]),e._v(" "),a("h3",{attrs:{id:"widerperson-a-diverse-dataset-for-dense-pedestrian-detection-in-the-wild"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#widerperson-a-diverse-dataset-for-dense-pedestrian-detection-in-the-wild"}},[e._v("#")]),e._v(" WiderPerson: A Diverse Dataset for Dense Pedestrian Detection in the Wild")]),e._v(" "),a("p",[a("img",{attrs:{src:"http://www.cbsr.ia.ac.cn/users/sfzhang/WiderPerson/files/intro.jpg",alt:""}})]),e._v(" "),a("p",[a("strong",[e._v("Fonte:")]),e._v(" "),a("a",{attrs:{href:"http://www.cbsr.ia.ac.cn/users/sfzhang/WiderPerson/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.cbsr.ia.ac.cn/users/sfzhang/WiderPerson/"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("strong",[e._v("Sobre:")]),e._v(' O conjunto de dados WiderPerson é um conjunto de dados de referência de detecção de pedestres em "estado selvagem" ('),a("em",[e._v("in the wild")]),e._v("), cujas imagens são selecionadas a partir de uma ampla gama de cenários, não mais limitados ao cenário de tráfego. Foram escolhidas 13.382 imagens e rotuladas cerca de 400 mil anotações com vários tipos de oclusões")]),e._v(" "),a("p",[a("strong",[e._v("Citação:")]),e._v(" S. Zhang, Y. Xie, J. Wan, H. Xia, S. Z. Li, and G. Guo, “Widerperson:A  diverse  dataset  for  dense  pedestrian  detection  in  the  wild,” IEEETransactions on Multimedia (TMM), 2019.")]),e._v(" "),a("h3",{attrs:{id:"caltech-pedestrian-detection-benchmark"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#caltech-pedestrian-detection-benchmark"}},[e._v("#")]),e._v(" Caltech Pedestrian Detection Benchmark")]),e._v(" "),a("p",[a("img",{attrs:{src:"http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/peds01_web.jpg",alt:""}})]),e._v(" "),a("p",[a("strong",[e._v("Fonte:")]),e._v(" "),a("a",{attrs:{href:"http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("strong",[e._v("Sobre:")]),e._v(" O "),a("em",[e._v("Caltech Pedestrian Dataset")]),e._v(" consiste em aproximadamente 10 horas de vídeo obtidos de um veículo em trânsito regular em um ambiente urbano. Cerca de 250.000 quadros (em 137 segmentos de aproximadamente minutos) com um total de 350.000 "),a("em",[e._v("bounding boxes")]),e._v(" e 2.300 pedestres únicos foram anotados. A anotação inclui correspondência temporal entre "),a("em",[e._v("bounding boxes")]),e._v(" e rótulos de oclusão detalhados.")]),e._v(" "),a("p",[a("strong",[e._v("Citação:")]),e._v(" ...")])])}),[],!1,null,null,null);t.default=r.exports}}]);