(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{415:function(e,a,o){e.exports=o.p+"assets/img/fit.2c2f2983.png"},416:function(e,a,o){e.exports=o.p+"assets/img/predict.bf8734d4.png"},447:function(e,a,o){"use strict";o.r(a);var s=o(56),t=Object(s.a)({},(function(){var e=this,a=e.$createElement,s=e._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h2",{attrs:{id:"introducao"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#introducao"}},[e._v("#")]),e._v(" Introdução")]),e._v(" "),s("p",[e._v("Esse relatório tem como objetivo fazer um overview explicando os processos utilizados do inicío até o fim de um treinamento utilizando o Keras. Futuramente será feito um relatório entrando em detalhes mais profundos como parâmetros, algorítmos de perda/ otimização e etc.")]),e._v(" "),s("p",[e._v("Keras é uma API de redes neurais de alto nível, escrita em Python e capaz de executar sobre TensorFlow, CNTK ou Theano.")]),e._v(" "),s("h2",{attrs:{id:"datasets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#datasets"}},[e._v("#")]),e._v(" Datasets")]),e._v(" "),s("p",[e._v("Antes de iniciar, é preciso escolher um dataset. O próprio Keras já disponibiliza alguns:")]),e._v(" "),s("ul",[s("li",[s("p",[s("strong",[e._v("boston_housing module")]),e._v(": Conjunto de dados de regressão do preço da habitação em Boston.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("cifar10 module")]),e._v(": Conjunto de dados de classificação de imagens pequenas CIFAR10 (60000 imagens coloridas de 32 x 32 em 10 classes, com 6000 imagens por classe).")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("cifar100 module")]),e._v(": Conjunto de dados de classificação de imagens pequenas CIFAR100 (assim como o CIFAR-10, exceto que possui 100 classes contendo 600 imagens cada).")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("fashion_mnist module")]),e._v(": Dataset Fashion-MNIST (conjunto de dados das imagens dos itens da loja "),s("strong",[e._v("Zalando")]),e._v(" - consistindo em um conjunto de treinamento de 60.000 exemplos e um conjunto de testes de 10.000 exemplos. Cada exemplo é uma imagem em escala de cinza de 28 x 28, associada a um rótulo de 10 classes).")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("imdb module")]),e._v(": Conjunto de dados de classificação de sentimentos do IMDB.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("mnist module")]),e._v(": Conjunto de dados de dígitos manuscritos MNIST.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("reuters module")]),e._v(": Conjunto de dados de classificação de tópicos da "),s("strong",[e._v("Reuters")]),e._v(".")])])]),e._v(" "),s("p",[e._v("Para o curso foi utilizado o "),s("strong",[e._v("fashion_mnist module")]),e._v(".")]),e._v(" "),s("h2",{attrs:{id:"sequential"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sequential"}},[e._v("#")]),e._v(" Sequential")]),e._v(" "),s("p",[e._v("O modelo Sequencial ("),s("strong",[e._v("keras.Sequential")]),e._v(") é uma pilha linear de camadas.")]),e._v(" "),s("p",[e._v("É possível criar um modelo seqüencial passando uma lista de instâncias de camada para o construtor:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[e._v("modelo = keras.Sequential([\n    # Camada de entrada\n    keras.layers.Flatten(input_shape = (28,28)), # As imagens, de 28 por 28 pixels (input_shape = tamanho das entradas).\n    \n    # Processamento (camada do tipo dense,\n    keras.layers.Dense(256, activation = tf.nn.relu), # => Não há um número exato, ele deve ser testado e ajustado.\n\n    # 'Adormecer' alguns itens, normalizando o modelo\n    keras.layers.Dropout(0.2),\n    \n    # Saida\n    keras.layers.Dense(10, activation = tf.nn.softmax), # => Aqui eu coloco 10 porque eu tenho 10 tipos de categorias.\n])\n")])])]),s("p",[e._v("Os modelos em Keras são definidos como uma sequência de camadas.")]),e._v(" "),s("h3",{attrs:{id:"camada-flatten"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#camada-flatten"}},[e._v("#")]),e._v(" Camada Flatten")]),e._v(" "),s("p",[e._v("O "),s("strong",[e._v("keras.Flatten")]),e._v(" basicamente "),s("em",[e._v("nivela a entrada")]),e._v(". Achatar um tensor significa remover todas as dimensões, exceto uma. É exatamente isso que a camada "),s("strong",[e._v("Flatten")]),e._v(" faz.")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://i.stack.imgur.com/IBt6j.jpg",alt:""}})]),e._v(" "),s("h3",{attrs:{id:"camada-dense"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#camada-dense"}},[e._v("#")]),e._v(" Camada Dense")]),e._v(" "),s("p",[e._v("Conforme a documentação, "),s("em",[e._v("Apenas a sua camada NN comum, densamente conectada")]),e._v(" (NN = neural network). Ou seja, a cadada "),s("em",[e._v("core")]),e._v(". É a implementação da equação:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[e._v("output = activation(dot(input, kernel) + bias)\n")])])]),s("p",[e._v("Isso significa que estamos pegando o produto escalar entre nosso tensor de entrada e qualquer que seja a matriz de núcleo de peso que esteja presente em nossa camada densa. Em seguida, adicionamos um vetor de viés  e realizamos uma ativação por elemento dos valores de saída ("),s("strong",[e._v("relu no nosso caso")]),e._v(").")]),e._v(" "),s("h3",{attrs:{id:"dropout"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dropout"}},[e._v("#")]),e._v(" Dropout")]),e._v(" "),s("p",[e._v("Aplica o Dropout à entrada.")]),e._v(" "),s("p",[e._v("O "),s("strong",[e._v("Dropout")]),e._v(" (abandono) consiste em definir aleatoriamente uma taxa de fração das unidades de entrada como 0 a cada atualização durante o tempo de treinamento, o que ajuda a evitar o ajuste excessivo (overfitting).")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://hackernoon.com/hn-images/1*L392ucqge-zTsOJYieRN7A.png",alt:""}})]),e._v(" "),s("p",[s("strong",[e._v("Overfitting:")]),e._v(" Quando um modelo é treinado com muitos dados, ele começa a aprender com o ruído e as entradas de dados imprecisas em nosso conjunto de dados. Em seguida, o modelo não categoriza os dados corretamente, devido a muitos detalhes e ruídos.")]),e._v(" "),s("h2",{attrs:{id:"compile"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#compile"}},[e._v("#")]),e._v(" Compile")]),e._v(" "),s("p",[e._v("Antes de treinar um modelo, é preciso configurar o processo de aprendizado, que é feito pelo método de compilação. Ele recebe três argumentos:")]),e._v(" "),s("ul",[s("li",[s("p",[s("strong",[e._v("Um otimizador (optimizer)")]),e._v(". Pode ser o identificador de sequência de um otimizador existente (como rmsprop ou adagrad) ou uma instância da classe Optimizer.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("Uma função de perda (loss)")]),e._v(". Esse é o objetivo que o modelo tentará minimizar. Pode ser o identificador de sequência de uma função de perda existente (como categorical_crossentropy ou mse) ou pode ser uma função objetiva.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("Uma lista de métricas (metrics)")]),e._v(". Para qualquer problema de classificação, defina isso como métricas = ['precisão']. Uma métrica pode ser o identificador de sequência de uma métrica existente ou uma função de métrica personalizada.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[e._v("  modelo.compile(\n      # Otimizador\n      optimizer=adam, \n      \n      # Função de perda\n      loss='sparse_categorical_crossentropy',\n      \n      # métricas\n      metrics=['accuracy']\n  )\n")])])])])]),e._v(" "),s("h2",{attrs:{id:"training-fit"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#training-fit"}},[e._v("#")]),e._v(" Training (fit)")]),e._v(" "),s("p",[e._v("Após configurar e compilar o modelo, fazemos o treinamento dele com o "),s("strong",[e._v(".fit")]),e._v(". Conforme a documentação: "),s("em",[e._v("Treina o modelo para um número fixo de épocas (iterações em um conjunto de dados).")])]),e._v(" "),s("p",[e._v("O retorno é um objeto "),s("em",[e._v("History")]),e._v(". Seu atributo "),s("strong",[e._v("History.history")]),e._v(" é um registro de valores de perda de treinamento e valores de métricas em épocas sucessivas, bem como valores de perda de validação e valores de métricas de validação.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[e._v("historico = modelo.fit(imagens_treino, identificacoes_treino, epochs=5, validation_split=0.2)\n")])])]),s("p",[s("img",{attrs:{src:o(415),alt:""}})]),e._v(" "),s("h2",{attrs:{id:"predict"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#predict"}},[e._v("#")]),e._v(" Predict")]),e._v(" "),s("p",[e._v("Por fim, após toda a parte custosa do Deep Learning ter sido finalizada, podemos fazer as predições usando nosso modelo com o "),s("strong",[e._v(".predict")]),e._v(" . Segundo a documentação, o predict:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[e._v("Gera previsões de saída para as amostras de entrada.\n")])])]),s("p",[s("img",{attrs:{src:o(416),alt:""}})]),e._v(" "),s("h2",{attrs:{id:"referencias"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#referencias"}},[e._v("#")]),e._v(" Referências")]),e._v(" "),s("p",[e._v("[1] https://keras.io/")]),e._v(" "),s("p",[e._v("[2] https://www.dobitaobyte.com.br/rede-neural-com-keras-mais-anotacoes/")]),e._v(" "),s("p",[e._v("[3] https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras")]),e._v(" "),s("p",[e._v("[4] https://medium.com/@hunterheidenreich/understanding-keras-dense-layers-2abadff9b990")])])}),[],!1,null,null,null);a.default=t.exports}}]);